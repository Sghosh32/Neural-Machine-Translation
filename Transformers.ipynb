{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sghosh32/Neural-Machine-Translation/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73gyRywzQ2jO",
        "outputId": "b0e4820f-2242-4674-8ad3-c85fcad30e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 32.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z5yyzKx8xxU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import spacy\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import TranslationDataset, Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J8fVmnm8338",
        "outputId": "22c48f7d-16e5-4e7c-9aff-1e8ed7d9931a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook is running on cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Notebook is running on\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK3glZvo86EC"
      },
      "outputs": [],
      "source": [
        "SEED = 4444\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1sJqxt99B5_",
        "outputId": "ef169324-b41e-4731-8dde-01358dbbde4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.3.0/de_core_news_sm-3.3.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 510 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->de-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 19.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download de\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua6XN4Ts9DcQ"
      },
      "outputs": [],
      "source": [
        "de_model = spacy.load('de_core_news_sm')\n",
        "en_model = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD7J7kX59Fn4"
      },
      "outputs": [],
      "source": [
        "def de_tokenizer(sentence):\n",
        "    return [token.text for token in de_model.tokenizer(sentence)]\n",
        "\n",
        "def en_tokenizer(sentence):\n",
        "    return [token.text for token in en_model.tokenizer(sentence)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM9FTGB69G6Q",
        "outputId": "c17b0be2-1e4b-4824-fbca-6251ffd070c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "Source_Field = Field(eos_token = '<src_eos>', init_token = '<src_sos>', lower = True, tokenize = de_tokenizer, batch_first = True)\n",
        "Target_Field = Field(eos_token = '<trg_eos>', init_token = '<trg_sos>', lower = True, tokenize = en_tokenizer, batch_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yegK3ttMu3as",
        "outputId": "cbb79c85-5089-4656-ea54-b452c80ed80d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (Source_Field, Target_Field), root = 'data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZC8QFHFu902",
        "outputId": "b8ef31a8-df6f-4954-9923-f58c7b9a354f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vocab size: 7853 | Target vocab size: 5893\n"
          ]
        }
      ],
      "source": [
        "Source_Field.build_vocab(train_data, min_freq = 2)\n",
        "Target_Field.build_vocab(train_data, min_freq = 2)\n",
        "print(f\"Source vocab size: {len(Source_Field.vocab)} | Target vocab size: {len(Target_Field.vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3VT_xjmvJGj"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dimension, n_heads, dropout):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        self.hidden_dimension = hidden_dimension\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dimension = hidden_dimension // n_heads\n",
        "        self.fc_Q = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.fc_K = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.fc_V = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.fc_O = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.scale = math.sqrt(self.head_dimension)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.fc_Q(query)\n",
        "        K = self.fc_K(key)\n",
        "        V = self.fc_V(value)\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dimension).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dimension).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dimension).permute(0, 2, 1, 3)\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        output = self.fc_O(x.view(batch_size, -1, self.hidden_dimension))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pty4NU-fPTSN"
      },
      "outputs": [],
      "source": [
        "class PositionFeedForwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dimension, pff_dimension, dropout):\n",
        "        super(PositionFeedForwardLayer, self).__init__()\n",
        "        self.fc_1 = nn.Linear(hidden_dimension, pff_dimension)\n",
        "        self.fc_2 = nn.Linear(pff_dimension, hidden_dimension)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = torch.relu(self.fc_1(input))\n",
        "        output = self.fc_2(self.dropout(output))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWpVISZGu7Nz"
      },
      "outputs": [],
      "source": [
        "class Encoder_Layer(nn.Module):\n",
        "    def __init__(self, hidden_dimension, n_heads, pff_dimension, dropout):\n",
        "        super(Encoder_Layer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dimension, n_heads, dropout)\n",
        "        self.pff = PositionFeedForwardLayer(hidden_dimension, pff_dimension, dropout)\n",
        "        self.attention_normalized = nn.LayerNorm(hidden_dimension)\n",
        "        self.pff_normalized = nn.LayerNorm(hidden_dimension)\n",
        "        self.dropout = nn.Dropout\n",
        "\n",
        "    def forward(self, source, source_mask):\n",
        "        attention_output = self.self_attention(source, source, source, source_mask)\n",
        "        inter_output = self.attention_normalized(attention_output + source)\n",
        "        pff_output = self.pff(inter_output)\n",
        "        output = self.pff_normalized(pff_output + inter_output)\n",
        "        return output          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61afkuV0Xhwv"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, token_vocab_size, positional_vocab_size, hidden_dimension, encoder_heads, encoder_pff_dimension, num_layers, encoder_dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(token_vocab_size, hidden_dimension)\n",
        "        self.positional_embedding = nn.Embedding(positional_vocab_size, hidden_dimension)\n",
        "        self.encoder_layers = nn.ModuleList([Encoder_Layer(hidden_dimension, encoder_heads, encoder_pff_dimension, encoder_dropout) for i in range(num_layers)])\n",
        "        self.scale = math.sqrt(hidden_dimension)\n",
        "        self.dropout = nn.Dropout(encoder_dropout)\n",
        "\n",
        "    def forward(self, source, source_mask):\n",
        "        batch_size = source.shape[0]\n",
        "        source_length = source.shape[1]\n",
        "        token_embedding = self.token_embedding(source)\n",
        "        positional_tensor = torch.arange(0, source_length).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "        positional_embedding = self.positional_embedding(positional_tensor)\n",
        "        encoder_embedding = self.dropout(token_embedding * self.scale + positional_embedding)\n",
        "        encoder_state = encoder_embedding\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            encoder_state = encoder_layer(encoder_state, source_mask)\n",
        "        return encoder_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNabdg7Ldba2"
      },
      "outputs": [],
      "source": [
        "class Decoder_Layer(nn.Module):\n",
        "    def __init__(self, hidden_dimension, n_heads, pff_dimension, dropout):\n",
        "        super(Decoder_Layer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dimension, n_heads, dropout)\n",
        "        self.cross_attention = MultiHeadAttentionLayer(hidden_dimension, n_heads, dropout)\n",
        "        self.pff = PositionFeedForwardLayer(hidden_dimension, pff_dimension, dropout)\n",
        "        self.attention_norm1 = nn.LayerNorm(hidden_dimension)\n",
        "        self.attention_norm2 = nn.LayerNorm(hidden_dimension)\n",
        "        self.pff_normalized = nn.LayerNorm(hidden_dimension)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, target, target_mask, encoder_output, source_mask):\n",
        "        self_attention = self.self_attention(target, target, target, target_mask)\n",
        "        output1 = self.attention_norm1(self.dropout(self_attention) + target)\n",
        "        cross_attention = self.cross_attention(output1, encoder_output, encoder_output, source_mask)\n",
        "        output2 = self.attention_norm2(self.dropout(cross_attention) + output1)\n",
        "        pff_output = self.pff(output2)\n",
        "        output = self.pff_normalized(self.dropout(pff_output) + output2)\n",
        "        return output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGiQnMg4sJzL"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, token_vocab_size, positional_vocab_size, hidden_dimension, decoder_heads, decoder_pff_dimension, num_layers, decoder_dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(token_vocab_size, hidden_dimension)\n",
        "        self.positional_embedding = nn.Embedding(positional_vocab_size, hidden_dimension)\n",
        "        self.decoder_layers = nn.ModuleList([Decoder_Layer(hidden_dimension, decoder_heads, decoder_pff_dimension, decoder_dropout) for i in range(num_layers)])\n",
        "        self.fc = nn.Linear(hidden_dimension, token_vocab_size)\n",
        "        self.scale = math.sqrt(hidden_dimension)\n",
        "        self.dropout = nn.Dropout(decoder_dropout)\n",
        "\n",
        "    def forward(self, target, target_mask, encoder_output, source_mask):\n",
        "        batch_size = target.shape[0]\n",
        "        target_length = target.shape[1]\n",
        "        token_embedding = self.token_embedding(target)\n",
        "        positional_tensor = torch.arange(0, target_length).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "        positional_embedding = self.positional_embedding(positional_tensor)\n",
        "        decoder_embedding = self.dropout(token_embedding * self.scale + positional_embedding)\n",
        "        decoder_state = decoder_embedding\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            decoder_state = decoder_layer(decoder_state, target_mask, encoder_output, source_mask)\n",
        "        output = self.fc(decoder_state)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ycv_g7h470_6"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, source_padding_index, target_padding_index):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.source_padding_index = source_padding_index\n",
        "        self.target_padding_index = target_padding_index\n",
        "\n",
        "    def make_source_mask(self, src):\n",
        "        source_mask = (src != self.source_padding_index).unsqueeze(1).unsqueeze(2).to(device)\n",
        "        return source_mask\n",
        "\n",
        "    def make_target_mask(self, trg):\n",
        "        trg_length = trg.shape[1]\n",
        "        pad_mask = (trg != self.target_padding_index).unsqueeze(1).unsqueeze(2).to(device)\n",
        "        sub_mask = torch.tril(torch.ones((trg_length, trg_length), device = device)).bool()\n",
        "        target_mask = pad_mask & sub_mask\n",
        "        return target_mask\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        source_mask = self.make_source_mask(source)\n",
        "        target_mask = self.make_target_mask(target)\n",
        "        encoder_output = self.encoder(source, source_mask)\n",
        "        output = self.decoder(target, target_mask, encoder_output, source_mask)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-HEqyWO7Oub"
      },
      "outputs": [],
      "source": [
        "def Train(iterator, model, criterion, optimizer, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        source = batch.src\n",
        "        target = batch.trg\n",
        "        outputs = model(source, target[:, :-1])\n",
        "        outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
        "        targets = target[:, 1:].contiguous().view(-1).to(device)\n",
        "        batch_loss = criterion(outputs, targets)\n",
        "        batch_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += batch_loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWoXUk5R9HBh"
      },
      "outputs": [],
      "source": [
        "def Evaluate(iterator, model, criterion):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for _, batch in enumerate(iterator):\n",
        "            source = batch.src\n",
        "            target = batch.trg\n",
        "            outputs = model(source, target[:, :-1])\n",
        "            outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
        "            targets = target[:, 1:].contiguous().view(-1).to(device)\n",
        "            batch_loss = criterion(outputs, targets)\n",
        "            eval_loss += batch_loss.item()\n",
        "        return eval_loss/len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYyCK-kh914e",
        "outputId": "ec80fe75-1740-4bd0-c691-4521d21a1b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9t-Fe21-B2R",
        "outputId": "29e30434-c425-40f6-fd66-67996bee31ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training sequences:  29000\n",
            "Number of Test sequences:  1000\n",
            "Number of Validation sequences:  1014\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Training sequences: \", len(train_data.examples))\n",
        "print(\"Number of Test sequences: \", len(test_data.examples))\n",
        "print(\"Number of Validation sequences: \", len(valid_data.examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHmscuqp-GRv"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "LR = 0.0005\n",
        "CLIP = 1\n",
        "SOURCE_VOCAB_SIZE = len(Source_Field.vocab)\n",
        "TARGET_VOCAB_SIZE = len(Target_Field.vocab)\n",
        "HIDDEN_DIMENSION = 256\n",
        "ENCODER_PFF_DIMENSION = 512\n",
        "DECODER_PFF_DIMENSION = 512\n",
        "ENCODER_HEADS = 8\n",
        "DECODER_HEADS = 8\n",
        "ENCODER_DROPOUT = 0.1\n",
        "DECODER_DROPOUT = 0.1\n",
        "ENCODER_NUM_LAYERS = 3\n",
        "DECODER_NUM_LAYERS = 3\n",
        "MAX_LENGTH = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTNH_VR_-qIt"
      },
      "outputs": [],
      "source": [
        "source_padding_index = Source_Field.vocab.stoi[Source_Field.pad_token]\n",
        "target_padding_index = Target_Field.vocab.stoi[Target_Field.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = target_padding_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFXlp6sR_HCK"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(SOURCE_VOCAB_SIZE, MAX_LENGTH, HIDDEN_DIMENSION, ENCODER_HEADS, ENCODER_PFF_DIMENSION, ENCODER_NUM_LAYERS, ENCODER_DROPOUT).to(device)\n",
        "decoder = Decoder(TARGET_VOCAB_SIZE, MAX_LENGTH, HIDDEN_DIMENSION, DECODER_HEADS, DECODER_PFF_DIMENSION, DECODER_NUM_LAYERS, DECODER_DROPOUT).to(device)\n",
        "transformer = Transformer(encoder, decoder, source_padding_index, target_padding_index).to(device)\n",
        "optimizer = optim.Adam(transformer.parameters(), LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZHgt3J9AFBO"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTbyWSKDAWIV",
        "outputId": "6b7c9f5c-4dcf-4060-8b04-8409d65db842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (token_embedding): Embedding(7853, 256)\n",
              "    (positional_embedding): Embedding(100, 256)\n",
              "    (encoder_layers): ModuleList(\n",
              "      (0): Encoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): Encoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): Encoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (token_embedding): Embedding(5893, 256)\n",
              "    (positional_embedding): Embedding(100, 256)\n",
              "    (decoder_layers): ModuleList(\n",
              "      (0): Decoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (cross_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): Decoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (cross_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): Decoder_Layer(\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (cross_attention): MultiHeadAttentionLayer(\n",
              "          (fc_Q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_K): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_V): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_O): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (pff): PositionFeedForwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attention_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (pff_normalized): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=256, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "transformer.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2GSBb7iAfYr",
        "outputId": "934fd16d-adb1-4a12-9d80-18c6076f6a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,038,341 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(transformer):,} trainable parameters.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrF6ITOVBDzq",
        "outputId": "eb7cd6c1-5980-4b40-e390-622a205ea396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.0005, Hidden Dimmensions: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 4.2062 | Validation Loss: 2.9314\n",
            "Training PPL: 67.1029 | Validation PPL: 18.7544\n",
            "Training Loss: 2.7188 | Validation Loss: 2.2458\n",
            "Training PPL: 15.1623 | Validation PPL: 9.4475\n",
            "Training Loss: 2.1585 | Validation Loss: 1.9441\n",
            "Training PPL: 8.6580 | Validation PPL: 6.9876\n",
            "Training Loss: 1.8189 | Validation Loss: 1.7976\n",
            "Training PPL: 6.1650 | Validation PPL: 6.0352\n",
            "Training Loss: 1.5761 | Validation Loss: 1.7211\n",
            "Training PPL: 4.8359 | Validation PPL: 5.5909\n",
            "Training Loss: 1.3935 | Validation Loss: 1.6957\n",
            "Training PPL: 4.0290 | Validation PPL: 5.4505\n",
            "Training Loss: 1.2421 | Validation Loss: 1.6733\n",
            "Training PPL: 3.4629 | Validation PPL: 5.3295\n",
            "Training Loss: 1.1158 | Validation Loss: 1.6909\n",
            "Training PPL: 3.0521 | Validation PPL: 5.4244\n",
            "Training Loss: 1.0095 | Validation Loss: 1.6842\n",
            "Training PPL: 2.7441 | Validation PPL: 5.3883\n",
            "Training Loss: 0.9163 | Validation Loss: 1.7041\n",
            "Training PPL: 2.4999 | Validation PPL: 5.4964\n"
          ]
        }
      ],
      "source": [
        "print(f\"Learning Rate: {LR}, Hidden Dimmensions: {HIDDEN_DIMENSION}\")\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "prev_epoch = 1\n",
        "min_losses = [float('inf'), float('inf')]\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss = Train(train_iterator, transformer, criterion, optimizer, CLIP)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_loss = Evaluate(test_iterator, transformer, criterion)\n",
        "    valid_losses.append(valid_loss)\n",
        "    if valid_loss < min_losses[0]:\n",
        "        min_losses[0] = valid_loss\n",
        "        min_losses[1] = train_loss\n",
        "    if epoch % int(NUM_EPOCHS / 10) == 0:\n",
        "        prev_epoch = epoch + 1\n",
        "        print(f\"Training Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}\")\n",
        "        print(f\"Training PPL: {math.exp(train_loss):.4f} | Validation PPL: {math.exp(valid_loss):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuz8mTcACHFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9fe34e-8855-45f1-a7b3-96ad9ee0367f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.7041 | Test PPL: 5.4964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ],
      "source": [
        "transformer.eval()\n",
        "test_loss = Evaluate(test_iterator, transformer, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test PPL: {math.exp(test_loss):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBNvRsIjCI66"
      },
      "outputs": [],
      "source": [
        "def sentence_translation(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    model.eval()\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_source_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_target_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(trg_tensor, trg_mask, enc_src, src_mask)\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24zInVmsp37d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1465d9-ef4b-4e36-8002-f6defee28d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German Sentence:  ein kleiner junge in einem blauen t-shirt wirft einen football .\n",
            "Predicted Translation:  a young boy in a blue shirt throwing a football .\n",
            "Actual Translation:  a little boy at camp , in a blue shirt , throwing a football .\n"
          ]
        }
      ],
      "source": [
        "ind = int(random.random() * len(train_data.examples))\n",
        "example = train_data.examples[ind + 1]\n",
        "source_sentence = example.src\n",
        "target_sentence = example.trg\n",
        "print(\"German Sentence: \", ' '.join(source_sentence))\n",
        "translation = sentence_translation(source_sentence, Source_Field, Target_Field, transformer, device)\n",
        "print(\"Predicted Translation: \", ' '.join(translation[:-1]))\n",
        "print(\"Actual Translation: \", ' '.join(target_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGvU2U8DqiEO"
      },
      "outputs": [],
      "source": [
        "def Calculate_BLEU(data, source_field, target_field, model):\n",
        "    targets = []\n",
        "    predicted_targets = []\n",
        "    for datum in data:\n",
        "        source_sentence = vars(datum)['src']\n",
        "        target_sentence = vars(datum)['trg']\n",
        "        predicted_target = sentence_translation(source_sentence, source_field, target_field, model, device)\n",
        "        predicted_targets.append(predicted_target[:-1])\n",
        "        targets.append([target_sentence])\n",
        "    return bleu_score(predicted_targets, targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score_test = Calculate_BLEU(test_data, Source_Field, Target_Field, transformer)\n",
        "print(f\"BLEU score on Testing Data: {bleu_score_test*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lONDMAYSrZGD",
        "outputId": "d40cbdca-c850-42f6-b10b-d99274756184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score on Testing Data: 36.31\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformers",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}